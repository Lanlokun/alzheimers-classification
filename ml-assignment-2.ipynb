{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10889949,"sourceType":"datasetVersion","datasetId":6767223}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport time\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\n\n# Set seed for reproducibility\nnp.random.seed(42)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:17:14.118185Z","iopub.execute_input":"2025-06-05T22:17:14.118490Z","iopub.status.idle":"2025-06-05T22:17:38.733989Z","shell.execute_reply.started":"2025-06-05T22:17:14.118468Z","shell.execute_reply":"2025-06-05T22:17:38.733410Z"}},"outputs":[{"name":"stderr","text":"2025-06-05 22:17:19.908438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749161840.439246      75 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749161840.567771      75 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Dataset paths (adjust if needed)\nbase_path = '/kaggle/input/best-alzheimer-mri-dataset-99-accuracy/Combined Dataset'\ntrain_path = os.path.join(base_path, 'train')\ntest_path = os.path.join(base_path, 'test')\n\n# Image generators with rescaling and validation split\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load training and validation sets\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(176, 208),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True)\n\nval_generator = train_datagen.flow_from_directory(\n    train_path,\n    target_size=(176, 208),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False)\n\n# Load test set\ntest_generator = test_datagen.flow_from_directory(\n    test_path,\n    target_size=(176, 208),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:18:31.473752Z","iopub.execute_input":"2025-06-05T22:18:31.474683Z","iopub.status.idle":"2025-06-05T22:18:41.470207Z","shell.execute_reply.started":"2025-06-05T22:18:31.474654Z","shell.execute_reply":"2025-06-05T22:18:41.469619Z"}},"outputs":[{"name":"stdout","text":"Found 8192 images belonging to 4 classes.\nFound 2048 images belonging to 4 classes.\nFound 1279 images belonging to 4 classes.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Load pretrained VGG16 without top layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(176, 208, 3))\n\n# Use output of last pooling layer as features\nfeature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:18:50.924844Z","iopub.execute_input":"2025-06-05T22:18:50.925114Z","iopub.status.idle":"2025-06-05T22:18:51.183666Z","shell.execute_reply.started":"2025-06-05T22:18:50.925073Z","shell.execute_reply":"2025-06-05T22:18:51.183054Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def extract_features(generator, sample_count):\n    batch_size = generator.batch_size\n    num_batches = int(np.ceil(sample_count / batch_size))\n    \n    features = np.zeros((sample_count, 5, 6, 512))\n    labels = np.zeros((sample_count, generator.num_classes))\n    \n    i = 0\n    for inputs_batch, labels_batch in generator:\n        batch_len = inputs_batch.shape[0]\n        features_batch = feature_extractor.predict(inputs_batch, verbose=0)\n        \n        features[i:i+batch_len] = features_batch\n        labels[i:i+batch_len] = labels_batch\n        \n        i += batch_len\n        if i >= sample_count:\n            break\n    \n    return features, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:18:53.141805Z","iopub.execute_input":"2025-06-05T22:18:53.142393Z","iopub.status.idle":"2025-06-05T22:18:53.147037Z","shell.execute_reply.started":"2025-06-05T22:18:53.142367Z","shell.execute_reply":"2025-06-05T22:18:53.146444Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_samples = train_generator.samples\nval_samples = val_generator.samples\ntest_samples = test_generator.samples\n\ntrain_features, train_labels = extract_features(train_generator, train_samples)\nval_features, val_labels = extract_features(val_generator, val_samples)\ntest_features, test_labels = extract_features(test_generator, test_samples)\n\n# Flatten features\ntrain_features_flat = train_features.reshape(train_samples, -1)\nval_features_flat = val_features.reshape(val_samples, -1)\ntest_features_flat = test_features.reshape(test_samples, -1)\n\n# Convert one-hot labels to categorical\ntrain_labels_cat = np.argmax(train_labels, axis=1)\nval_labels_cat = np.argmax(val_labels, axis=1)\ntest_labels_cat = np.argmax(test_labels, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:18:56.792954Z","iopub.execute_input":"2025-06-05T22:18:56.793258Z","iopub.status.idle":"2025-06-05T22:22:02.803698Z","shell.execute_reply.started":"2025-06-05T22:18:56.793237Z","shell.execute_reply":"2025-06-05T22:22:02.803050Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1749161937.475489     161 service.cc:148] XLA service 0x7b3600087900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1749161937.476882     161 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749161937.476902     161 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749161937.691864     161 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1749161946.819900     161 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"scaler = StandardScaler()\ntrain_scaled = scaler.fit_transform(train_features_flat)\nval_scaled = scaler.transform(val_features_flat)\ntest_scaled = scaler.transform(test_features_flat)\n\npca = PCA(n_components=50)\ntrain_pca = pca.fit_transform(train_scaled)\nval_pca = pca.transform(val_scaled)\ntest_pca = pca.transform(test_scaled)\n\nprint(f\"PCA explained variance ratio (first 50 components): {np.sum(pca.explained_variance_ratio_):.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    \"Decision Tree\": DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, class_weight='balanced', random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=10, class_weight='balanced', random_state=42, n_jobs=-1),\n    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, max_depth=5, min_samples_split=10, class_weight='balanced', random_state=42, n_jobs=-1),\n    \"XGBoost\": XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, objective='multi:softmax', random_state=42, tree_method='gpu_hist')\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport json\n\ndef evaluate_model(model, X_train, y_train, X_val, y_val, model_name, save_dir='/kaggle/working/model_results'):\n    import os\n    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n    import time\n    \n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n        \n    start_time = time.time()\n    \n    # Train model\n    model.fit(X_train, y_train)\n    train_time = time.time() - start_time\n    \n    # Predictions\n    val_pred = model.predict(X_val)\n    train_pred = model.predict(X_train)\n    \n    # Cross-validation (5-fold)\n    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n    \n    # Metrics dictionary\n    metrics = {\n        'model': model_name,\n        'train_accuracy': accuracy_score(y_train, train_pred),\n        'val_accuracy': accuracy_score(y_val, val_pred),\n        'cv_mean_accuracy': np.mean(cv_scores),\n        'cv_std_accuracy': np.std(cv_scores),\n        'training_time': train_time\n    }\n    \n    # Save classification report as text file\n    class_report = classification_report(y_val, val_pred, target_names=list(test_generator.class_indices.keys()))\n    with open(f\"{save_dir}/{model_name}_classification_report.txt\", \"w\") as f:\n        f.write(class_report)\n    \n    # Save confusion matrix plot\n    cm = confusion_matrix(y_val, val_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(test_generator.class_indices.keys()))\n    disp.plot(cmap='Blues')\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig(f\"{save_dir}/{model_name}_confusion_matrix.png\")\n    plt.close()\n    \n    # Save metrics as JSON for later easy parsing\n    with open(f\"{save_dir}/{model_name}_metrics.json\", \"w\") as f:\n        json.dump(metrics, f)\n    \n    print(f\"\\n{model_name} Performance:\")\n    print(\"Validation Set Classification Report:\")\n    print(class_report)\n    \n    return metrics\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = []\nsave_directory = '/kaggle/working/model_results'\n\nfor name, model in models.items():\n    metrics = evaluate_model(model, train_pca, train_labels_cat, val_pca, val_labels_cat, name, save_dir=save_directory)\n    results.append(metrics)\n\nresults_df = pd.DataFrame(results).sort_values('val_accuracy', ascending=False)\n\nprint(\"\\nModel Performance Comparison:\")\ndisplay(results_df)\n\n# Save overall summary dataframe as CSV\nresults_df.to_csv(f\"{save_directory}/model_comparison_summary.csv\", index=False)\nprint(f\"Saved overall results summary to {save_directory}/model_comparison_summary.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pick best model by validation accuracy\nbest_model_name = results_df.iloc[0]['model']\nbest_model = models[best_model_name]\n\n# Retrain on full train+val data\nX_full_train = np.vstack([train_pca, val_pca])\ny_full_train = np.hstack([train_labels_cat, val_labels_cat])\n\nbest_model.fit(X_full_train, y_full_train)\n\n# Evaluate on test set\ntest_pred = best_model.predict(test_pca)\ntest_acc = accuracy_score(test_labels_cat, test_pred)\n\nprint(f\"\\nBest Model: {best_model_name}\")\nprint(f\"Test Set Accuracy: {test_acc:.4f}\")\nprint(classification_report(test_labels_cat, test_pred, target_names=test_generator.class_indices.keys()))\n\ncm = confusion_matrix(test_labels_cat, test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\ndisp.plot(cmap='Blues')\nplt.title(f'{best_model_name} Test Set Confusion Matrix')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df.to_csv('/kaggle/working/model_evaluation_results.csv', index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Path to final results directory\nfinal_results_dir = \"/kaggle/working/model_results\"\nzip_file_path = \"/kaggle/working/model_results.zip\"\n\n# Create ZIP archive\nshutil.make_archive(base_name=zip_file_path.replace(\".zip\", \"\"), \n                    format=\"zip\", \n                    root_dir=final_results_dir)\n\nprint(f\"Zipped results folder created at: {zip_file_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from graphviz import Digraph\n\n# Create a new directed graph\ndot = Digraph(comment='Alzheimer MRI Classification Pipeline', format='png')\n\n# Set graph attributes for better readability\ndot.attr(rankdir='TB', size='8,10', dpi='300')\ndot.attr('node', shape='box', style='filled', fillcolor='lightblue', fontsize='12')\ndot.attr('edge', fontsize='10')\n\n# Define nodes for each pipeline step\ndot.node('A', 'Load MRI Images\\n(ImageDataGenerator)')\ndot.node('B', 'Feature Extraction\\n(VGG16 without top layers)')\ndot.node('C', 'Flatten Features\\n(Reshape to 1D)')\ndot.node('D', 'Scale Features\\n(StandardScaler)')\ndot.node('E', 'Dimensionality Reduction\\n(PCA, 50 components)')\ndot.node('F', 'Train Classifiers\\n(Decision Tree, Random Forest,\\nExtra Trees, XGBoost)')\ndot.node('G', 'Evaluate Models\\n(Validation Accuracy,\\nCross-Validation, Confusion Matrix)')\ndot.node('H', 'Select Best Model\\n(Highest Validation Accuracy)')\ndot.node('I', 'Retrain on Train+Val\\n(Test on Test Set)')\n\n# Define edges to represent the flow\ndot.edges(['AB', 'BC', 'CD', 'DE', 'EF', 'FG', 'GH', 'HI'])\n\n# Save the plot\ndot.render('alzheimer_mri_pipeline', view=False, cleanup=True)\n\nprint(\"Pipeline plot saved as 'alzheimer_mri_pipeline.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:11:07.464282Z","iopub.execute_input":"2025-06-05T22:11:07.464891Z","iopub.status.idle":"2025-06-05T22:11:07.984955Z","shell.execute_reply.started":"2025-06-05T22:11:07.464861Z","shell.execute_reply":"2025-06-05T22:11:07.984266Z"}},"outputs":[{"name":"stdout","text":"Pipeline plot saved as 'alzheimer_mri_pipeline.png'\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\ndef plot_model_performance(results_df, save_dir='/kaggle/working/model_results'):\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n\n    # Set up the plot\n    plt.figure(figsize=(10, 6))\n    models = results_df['model']\n    x = np.arange(len(models))  # Model indices\n    width = 0.25  # Bar width\n\n    # Plot bars for each metric\n    plt.bar(x - width, results_df['train_accuracy'], width, label='Train Accuracy', color='#36A2EB')\n    plt.bar(x, results_df['val_accuracy'], width, label='Validation Accuracy', color='#FF6384')\n    plt.bar(x + width, results_df['cv_mean_accuracy'], width, label='CV Mean Accuracy', color='#FFCE56')\n\n    # Add error bars for CV standard deviation\n    plt.errorbar(x + width, results_df['cv_mean_accuracy'], yerr=results_df['cv_std_accuracy'], \n                 fmt='none', ecolor='black', capsize=3)\n\n    # Customize plot\n    plt.xlabel('Models')\n    plt.ylabel('Accuracy')\n    plt.title('Model Performance Comparison')\n    plt.xticks(x, models, rotation=45)\n    plt.legend()\n    plt.tight_layout()\n\n    # Save plot\n    plt.savefig(f\"{save_dir}/model_performance_comparison.png\")\n    plt.close()\n\n    print(f\"Model performance plot saved to {save_dir}/model_performance_comparison.png\")\n\n\nplot_model_performance(results_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T22:15:42.101147Z","iopub.execute_input":"2025-06-05T22:15:42.101720Z","iopub.status.idle":"2025-06-05T22:15:43.504388Z","shell.execute_reply.started":"2025-06-05T22:15:42.101696Z","shell.execute_reply":"2025-06-05T22:15:43.503381Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_75/2935027857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Example usage (call after your loop over models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Assuming results_df, pca, best_model, and best_model_name are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mgenerate_additional_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/working/model_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"],"ename":"NameError","evalue":"name 'results_df' is not defined","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}